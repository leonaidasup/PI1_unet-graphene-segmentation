{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4PWHYAwlE-X"
      },
      "source": [
        "## Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXR6uK4rlHUy",
        "outputId": "7013dfb0-16d0-4ebb-be35-29a370e71295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/155.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/868.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/89.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Instalar dependencias\n",
        "!pip install -q roboflow pycocotools segmentation-models-pytorch albumentations==1.4.7 torchmetrics==1.4.0.post0 onnx onnxruntime matplotlib seaborn scikit-learn\n",
        "\n",
        "# Dataset\n",
        "from roboflow import Roboflow\n",
        "from pycocotools.coco import COCO\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# B√°sicas\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# M√©tricas\n",
        "from torchmetrics import JaccardIndex\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from tqdm.auto import tqdm\n",
        "import time, copy\n",
        "\n",
        "# Augmentations\n",
        "import cv2\n",
        "\n",
        "# M√©tricas\n",
        "from torchmetrics import JaccardIndex\n",
        "# üí° AGREGADO: Importaciones para curvas PR y de Calibraci√≥n\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_recall_curve, auc\n",
        "from sklearn.calibration import calibration_curve\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QttM6opJS5y"
      },
      "outputs": [],
      "source": [
        "# Comprobar GPU\n",
        "print(\"GPU disponible:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtNPlUOdIU-7"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEp-wxAaKsKd"
      },
      "source": [
        "### Descargar Dataset de Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nze_F2U_lJm-"
      },
      "outputs": [],
      "source": [
        "ROBOFLOW_API_KEY = \"x8f94bsxo45XbBc5XzuI\"\n",
        "WORKSPACE_NAME = \"integrador-i\"\n",
        "PROJECT_NAME = \"2d-materials-segmentation-zrowi\"\n",
        "VERSION_NUMBER = 2\n",
        "DATASET_FORMAT = \"coco-segmentation\"\n",
        "\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(WORKSPACE_NAME).project(PROJECT_NAME)\n",
        "dataset = project.version(VERSION_NUMBER).download(DATASET_FORMAT)\n",
        "\n",
        "print(\"\\nDataset descargado en:\", dataset.location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si_i3wezJ5vX"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1wgpc0dJ4s4"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 512\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    # Redimensionar y rellenar\n",
        "    A.LongestMaxSize(max_size=IMAGE_SIZE, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "\n",
        "    # Transformaciones geom√©tricas suaves\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.05, rotate_limit=5, p=0.5),\n",
        "\n",
        "    # Augmentations suaves espec√≠ficas para microscop√≠a\n",
        "    A.RandomBrightnessContrast(p=0.7, brightness_limit=0.25, contrast_limit=0.25),\n",
        "    A.HueSaturationValue(p=0.3, hue_shift_limit=5, sat_shift_limit=15, val_shift_limit=15),\n",
        "\n",
        "    # Ruido/blur ligero para microscop√≠a\n",
        "    A.GaussianBlur(p=0.1, blur_limit=(1,3)),\n",
        "    A.GaussNoise(p=0.2, var_limit=(5, 15)),\n",
        "\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "eval_transform = A.Compose([\n",
        "    A.LongestMaxSize(max_size=IMAGE_SIZE, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nrAzde1KfOk"
      },
      "source": [
        "### Creaci√≥n de los Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHBLiDbqKCuU"
      },
      "outputs": [],
      "source": [
        "def coco_image_info(coco_obj):\n",
        "    for img_id in coco_obj.getImgIds():\n",
        "        yield coco_obj.loadImgs([img_id])[0]\n",
        "\n",
        "def build_mask(coco_obj, image_info):\n",
        "    # Crea m√°scara de tama√±o (H,W) con enteros en [0, num_classes-1]\n",
        "    anns_ids = coco_obj.getAnnIds(imgIds=[image_info[\"id\"]])\n",
        "    anns = coco_obj.loadAnns(anns_ids)\n",
        "    mask = np.zeros((image_info[\"height\"], image_info[\"width\"]), dtype=np.uint8)\n",
        "\n",
        "    for ann in anns:\n",
        "        original_cat_id = ann[\"category_id\"]\n",
        "        if original_cat_id in cat_id_to_index:\n",
        "            cat_idx = cat_id_to_index[original_cat_id]\n",
        "            rle = coco_obj.annToRLE(ann)\n",
        "            m = coco_obj.annToMask(ann)  # (H,W) binaria\n",
        "            mask[m == 1] = cat_idx\n",
        "\n",
        "    return mask\n",
        "\n",
        "data_dir = Path(dataset.location) # Ubicaci√≥n del Dataset\n",
        "SPLITS = [\"train\", \"valid\", \"test\"]\n",
        "ANNOTATION_FILENAME = \"_annotations.coco.json\"\n",
        "\n",
        "# Cargar annotations de COCO por split\n",
        "coco_dict = {}\n",
        "for split in SPLITS:\n",
        "    ann_path = data_dir / split / ANNOTATION_FILENAME\n",
        "    coco_dict[split] = COCO(str(ann_path))\n",
        "\n",
        "# Mapeo: category_id -> 0..C-1\n",
        "categories = coco_dict[\"train\"].loadCats(coco_dict[\"train\"].getCatIds())\n",
        "categories[0]['name'] = 'background'\n",
        "\n",
        "# Mapeo: category_id -> √≠ndice secuencial\n",
        "cat_id_to_index = {}\n",
        "index_to_name = {}\n",
        "for i, cat in enumerate(categories):\n",
        "    cat_id_to_index[cat[\"id\"]] = i\n",
        "    index_to_name[i] = cat[\"name\"]\n",
        "\n",
        "num_classes = len(categories)\n",
        "print(\"Clases:\", index_to_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpwETM_MLEPM"
      },
      "outputs": [],
      "source": [
        "class GrapheneCocoDataset(Dataset):\n",
        "    def __init__(self, coco_obj, split, transform):\n",
        "        self.coco = coco_obj\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.images = list(coco_image_info(coco_obj))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        info = self.images[idx]\n",
        "        img_path = data_dir / self.split / info[\"file_name\"]\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = build_mask(self.coco, info)\n",
        "\n",
        "        # Albumentations espera dict\n",
        "        transformed = self.transform(image=image, mask=mask)\n",
        "        image_t = transformed[\"image\"]\n",
        "        mask_t = transformed[\"mask\"]\n",
        "\n",
        "        # A -> Tensor manual\n",
        "        image_t = torch.from_numpy(image_t.transpose(2,0,1)).float()\n",
        "        mask_t = torch.from_numpy(mask_t).long()\n",
        "        return image_t, mask_t, info[\"file_name\"]\n",
        "\n",
        "train_ds = GrapheneCocoDataset(coco_dict[\"train\"], \"train\", train_transform)\n",
        "val_ds   = GrapheneCocoDataset(coco_dict[\"valid\"], \"valid\", eval_transform)\n",
        "test_ds  = GrapheneCocoDataset(coco_dict[\"test\"], \"test\", eval_transform)\n",
        "\n",
        "print(\"Tama√±os:\", len(train_ds), len(val_ds), len(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3-8erWKKadz"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5nfJbZrlQIX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4  # Reducido para estabilidad\n",
        "NUM_WORKERS = 0  # Deshabilitado multiprocessing\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=False,\n",
        "    persistent_workers=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=False,\n",
        "    persistent_workers=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=False,\n",
        "    persistent_workers=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "print(\"Batches train:\", len(train_loader))\n",
        "print(\"Batch size:\", BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRXL9d9h6cUk"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-973SG_AlRd3"
      },
      "outputs": [],
      "source": [
        "# ============== MODELO UNET++ ==============\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modelo: U-Net++ con encoder Efficientnet-B4 pretrained en ImageNet\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b5\", # Para im√°genes de microscop√≠a\n",
        "    encoder_weights=\"imagenet\", # (INVESTIGAR)\n",
        "    in_channels=3,\n",
        "    classes=num_classes\n",
        ").to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xEU2UMT6YI0"
      },
      "source": [
        "### Funciones Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRJWam1F5jHW"
      },
      "outputs": [],
      "source": [
        "class BalancedFocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementaci√≥n optimizada de Focal Loss balanceado para segmentaci√≥n cient√≠fica.\n",
        "    Especialmente dise√±ado para manejar clases minoritarias como few-layer graphene.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.5, smooth=1e-8, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Pesos por clase para balancear\n",
        "        self.gamma = gamma  # Valor 2.5 para enfoque en ejemplos dif√≠ciles\n",
        "        self.smooth = smooth\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            logits: (B, C, H, W) - salidas del modelo\n",
        "            targets: (B, H, W) - ground truth labels\n",
        "        \"\"\"\n",
        "        # Convertir a probabilidades con temperature scaling\n",
        "        probs = F.softmax(logits / 1.2, dim=1)  # Temperatura 1.2 para mejor calibraci√≥n\n",
        "\n",
        "        # One-hot encoding de targets\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=logits.shape[1])\n",
        "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        # Cross entropy component con label smoothing ligero\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none', label_smoothing=0.05)\n",
        "\n",
        "        # Probabilidad de la clase correcta para cada pixel\n",
        "        pt = torch.sum(probs * targets_one_hot, dim=1)  # (B, H, W)\n",
        "        pt = torch.clamp(pt, self.smooth, 1.0 - self.smooth)  # Evitar log(0)\n",
        "\n",
        "        # Factor de modulaci√≥n focal: (1-pt)^gamma\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        # Aplicar pesos de clase si se proporcionan\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = torch.zeros_like(targets, dtype=torch.float32, device=targets.device)\n",
        "            for i, alpha_val in enumerate(self.alpha):\n",
        "                alpha_t[targets == i] = alpha_val\n",
        "            focal_loss = alpha_t * focal_weight * ce_loss\n",
        "        else:\n",
        "            focal_loss = focal_weight * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss mejorado con suavizado adaptativo\"\"\"\n",
        "    def __init__(self, smooth=1.0, ignore_index=None):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # logits: (B,C,H,W); targets: (B,H,W)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        targets_onehot = torch.nn.functional.one_hot(targets, num_classes=probs.shape[1]).permute(0,3,1,2).float()\n",
        "\n",
        "        if self.ignore_index is not None:\n",
        "            mask = targets != self.ignore_index\n",
        "            mask = mask.unsqueeze(1)\n",
        "            probs = probs * mask\n",
        "            targets_onehot = targets_onehot * mask\n",
        "\n",
        "        dims = (0,2,3)\n",
        "        intersection = (probs * targets_onehot).sum(dims)\n",
        "        cardinality = probs.sum(dims) + targets_onehot.sum(dims)\n",
        "        dice = (2.0 * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "def compute_class_weights(dataset, num_classes):\n",
        "    # Calculando pesos de clase\n",
        "    counts = torch.zeros(num_classes)\n",
        "    for i in range(len(dataset)):\n",
        "        _, mask, _ = dataset[i]\n",
        "        for c in range(num_classes):\n",
        "            counts[c] += (mask == c).sum().item()\n",
        "    freq = counts / counts.sum()\n",
        "    class_weights = (1.0 / np.sqrt(freq))\n",
        "    class_weights = class_weights / class_weights.sum() * len(class_weights)  # normalize\n",
        "\n",
        "    return class_weights\n",
        "\n",
        "class TverskyLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Tversky Loss - especialmente efectivo para clases desbalanceadas\n",
        "    Alpha controla False Negatives, Beta controla False Positives\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.7, beta=0.3, smooth=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Peso para FN (mayor = penaliza m√°s missed detections)\n",
        "        self.beta = beta    # Peso para FP (menor = menos penalizaci√≥n por false alarms)\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        targets_onehot = F.one_hot(targets, num_classes=probs.shape[1]).permute(0,3,1,2).float()\n",
        "\n",
        "        dims = (0,2,3)\n",
        "        intersection = (probs * targets_onehot).sum(dims)\n",
        "        fps = ((1 - targets_onehot) * probs).sum(dims)\n",
        "        fns = (targets_onehot * (1 - probs)).sum(dims)\n",
        "\n",
        "        tversky = (intersection + self.smooth) / (intersection + self.alpha * fns + self.beta * fps + self.smooth)\n",
        "        return 1 - tversky.mean()\n",
        "\n",
        "# Computar pesos de clase optimizados\n",
        "class_weights = compute_class_weights(train_ds, num_classes)\n",
        "class_weights[2] *= 50\n",
        "\n",
        "# Instanciar funciones de p√©rdida mejoradas\n",
        "focal_loss = BalancedFocalLoss(alpha=torch.tensor(class_weights).float().to(DEVICE), gamma=2.0)\n",
        "dice_loss = DiceLoss(smooth=1.0)\n",
        "tversky_loss = TverskyLoss(alpha=0.7, beta=0.3)  # Favorece recall sobre precision\n",
        "\n",
        "def combined_loss_v3(logits, targets):\n",
        "    \"\"\"\n",
        "    Funci√≥n de p√©rdida tri-h√≠brida optimizada para few-layer detection:\n",
        "    - 50% Focal Loss balanceado (para clases desbalanceadas)\n",
        "    - 30% Tversky Loss (para mejorar recall de clases minoritarias)\n",
        "    - 20% Dice Loss (para preservar forma de objetos)\n",
        "    \"\"\"\n",
        "    focal = focal_loss(logits, targets)\n",
        "    tversky = tversky_loss(logits, targets)\n",
        "    dice = dice_loss(logits, targets)\n",
        "    return 0.5 * focal + 0.3 * tversky + 0.2 * dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgnHs2ZD6j0N"
      },
      "source": [
        "### M√©tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKqlu6Na5k21"
      },
      "outputs": [],
      "source": [
        "def calculate_iou_scores(outputs, targets, num_classes):\n",
        "    iou = JaccardIndex(num_classes=num_classes, average='macro', task='multiclass').to(DEVICE)\n",
        "\n",
        "    # Calcular mIoU\n",
        "    iou.update(outputs, targets)\n",
        "    iou_score = iou.compute()\n",
        "\n",
        "    return iou_score.item()\n",
        "\n",
        "def evaluate_eval(val_loader, model, loss_fn, num_classes=2):\n",
        "    \"\"\"\n",
        "    Evaluates model on val_loader and returns loss, mIoU, and recall.\n",
        "    Returns: loss, miou, recall\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    losses, mious, recalls = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, *_ in val_loader:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "            loss = combined_loss_v3(logits, masks)\n",
        "\n",
        "            # Predictions\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # IoU (mean over classes, MACRO-promedio)\n",
        "            miou = calculate_iou_scores(preds, masks, num_classes)\n",
        "\n",
        "            # Recall (MACRO-promedio)\n",
        "            recall = recall_score(masks.cpu().numpy().ravel(), preds.cpu().numpy().ravel(), average=\"macro\")\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            mious.append(miou)\n",
        "            recalls.append(recall)\n",
        "\n",
        "    return np.mean(losses), np.mean(mious), np.mean(recalls)\n",
        "\n",
        "def evaluate_train(images, masks, model, loss_fn, num_classes):\n",
        "    images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "    with torch.amp.autocast(\"cuda\"):\n",
        "        logits = model(images)\n",
        "        loss = loss_fn(logits, masks)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "    miou = calculate_iou_scores(preds, masks, num_classes)\n",
        "    # üí° NOTA: Se asume que 'accuracy_score' est√° importada de sklearn\n",
        "    # accuracy = accuracy_score(masks.cpu().numpy().ravel(), preds.cpu().numpy().ravel())\n",
        "    # Tu codigo original ten√≠a un error de sintaxis en accuracy, lo dejaremos como estaba\n",
        "    # o mejor: lo arreglaremos si usas sklearn.metrics.accuracy_score\n",
        "    recall = recall_score(masks.cpu().numpy().ravel(), preds.cpu().numpy().ravel(), average=\"macro\")\n",
        "\n",
        "    return loss, miou, recall\n",
        "\n",
        "\n",
        "def evaluate_test_final(test_loader, model, num_classes):\n",
        "    \"\"\"\n",
        "    Eval√∫a el modelo en el conjunto de prueba y recolecta datos para curvas PR y de Calibraci√≥n.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_probas = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, *_ in tqdm(test_loader, desc=\"Evaluando para Curvas\"):\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "\n",
        "            # üí° Probas calibradas (con temperature scaling 1.2, como en BalancedFocalLoss)\n",
        "            probas = F.softmax(logits / 1.2, dim=1)\n",
        "\n",
        "            # Aplanar Probas (B, C, H, W) -> (N_pixeles, C)\n",
        "            all_probas.append(probas.permute(0, 2, 3, 1).reshape(-1, num_classes).cpu().numpy())\n",
        "\n",
        "            # Aplanar Targets (B, H, W) -> (N_pixeles,)\n",
        "            all_targets.append(masks.flatten().cpu().numpy())\n",
        "\n",
        "    all_probas_flat = np.concatenate(all_probas, axis=0)\n",
        "    all_targets_flat = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "    return all_probas_flat, all_targets_flat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FV2_65874-z"
      },
      "source": [
        "### Resumen del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaeMtjUm78db",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(\"Modelo optimizado para few-layer detection configurado\")\n",
        "print(f\"Pesos de clase aplicados: {[f'{w:.3f}' for w in class_weights]}\")\n",
        "print(\"Loss function: 50% Focal + 30% Tversky + 20% Dice\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCm0oKIz7-pB"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kbIBzvL5cj"
      },
      "source": [
        "### Hiperpar√°metros, Optimizer y Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D4CsJniMCGD"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 120   # M√°s √©pocas para convergencia con loss compleja\n",
        "LR = 6e-4     # Learning rate ligeramente menor para estabilidad\n",
        "WARMUP = 0.2  # 20% para warmup\n",
        "PATIENCE = 25 # Paciencia de √©pocas sin mejora\n",
        "\n",
        "# Optimizer con grupos de par√°metros diferenciados\n",
        "optimizer = AdamW(model.parameters(), lr=LR,\n",
        "                  weight_decay=0.01, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = OneCycleLR(optimizer, max_lr=6e-4, # LR m√°ximo conservador\n",
        "                      total_steps=total_steps, pct_start=WARMUP, # Tiempo para warm-up\n",
        "                      anneal_strategy='cos', # Cosine annealing suave\n",
        "                      div_factor=10, # LR inicial = max_lr/10\n",
        "                      final_div_factor=100 # LR final muy bajo\n",
        "                      )\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc6181rfM9_8"
      },
      "source": [
        "### Loop de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HISTORY_FILE = \"training_history.json\"\n",
        "\n",
        "with open(HISTORY_FILE, 'r') as f:\n",
        "    history = json.load(f)\n",
        "\n",
        "start_epoch = len(history[\"train_loss\"]) + 1\n",
        "best_miou = max(history[\"val_miou\"]) if history[\"val_miou\"] else 0.0\n",
        "\n",
        "best_weights = None\n",
        "bad_epochs = 0"
      ],
      "metadata": {
        "id": "-TaHRBlr014W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRiuh2dMlTM-"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    history[\"learning_rates\"].append(current_lr)\n",
        "\n",
        "    # Entrenamiento\n",
        "    model.train()\n",
        "    train_losses, train_ious, train_recalls = [], [], []\n",
        "    for images, masks, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        loss, miou, recall = evaluate_train(images, masks, model, combined_loss_v3, num_classes)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_ious.append(miou)\n",
        "        train_recalls.append(recall)\n",
        "\n",
        "    # M√©tricas de entrenamiento\n",
        "    history[\"train_loss\"].append(np.mean(train_losses))\n",
        "    history[\"train_miou\"].append(np.mean(train_ious))\n",
        "    history[\"train_recall\"].append(np.mean(train_recalls))\n",
        "\n",
        "    # Validaci√≥n\n",
        "    val_loss, val_miou, val_recall = evaluate_eval(val_loader, model, combined_loss_v3, num_classes)\n",
        "\n",
        "    history[\"val_miou\"].append(val_miou)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_recall\"].append(val_recall)\n",
        "\n",
        "    print(f\"[Epoch {epoch:2d}] TrainLoss={history['train_loss'][-1]:.4f}  ValLoss={val_loss:.4f}  ValmIoU={val_miou:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_miou > best_miou:\n",
        "        best_miou = val_miou\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "        bad_epochs = 0\n",
        "        torch.save({\n",
        "            'model_state_dict': best_weights,\n",
        "            'epoch': epoch,\n",
        "            'miou': best_miou,\n",
        "            'class_weights': class_weights,\n",
        "            'index_to_name': index_to_name\n",
        "        }, \"best_model.pt\")\n",
        "        print(f\"‚úì Modelo mejorado - mIoU: {best_miou:.4f}\")\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= PATIENCE:\n",
        "            print(f\"Early stopping en √©poca {epoch} (sin mejora por {PATIENCE} √©pocas)\")\n",
        "            break\n",
        "\n",
        "print(\"\\nENTRENAMIENTO COMPLETADO\")\n",
        "print(f\"Mejor mIoU validaci√≥n: {best_miou:.4f}\")\n",
        "model.load_state_dict(best_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1o5ALkNB8a"
      },
      "source": [
        "### Visualizaci√≥n del Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def med_des(array, txt = ''):\n",
        "  print(f\"Media {txt}: {np.mean(array[20:])}\\nDesviaci√≥n est√°ndar {txt}:{np.std(array[20:])}\\n\")"
      ],
      "metadata": {
        "id": "M36QKXgpFVJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nf7Bh9vlY1O"
      },
      "outputs": [],
      "source": [
        "# Figura 1: Loss\n",
        "print('Loss')\n",
        "med_des(history[\"train_loss\"], 'train')\n",
        "med_des(history[\"val_loss\"], 'val')\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history[\"train_loss\"], label=\"Train\")\n",
        "plt.plot(history[\"val_loss\"], label=\"Val\")\n",
        "plt.title(\"Perdida durante el Entrenamiento\")\n",
        "plt.xlabel(\"√âpocas\")\n",
        "plt.ylabel(\"Valor de P√©rdida H√≠brida Balanceada\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNnraMwj612o"
      },
      "outputs": [],
      "source": [
        "# Figura 2: mIoU\n",
        "print('MIou')\n",
        "med_des(history[\"train_miou\"], 'train')\n",
        "med_des(history[\"val_miou\"], 'val')\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history[\"train_miou\"], label=\"Train\")\n",
        "plt.plot(history[\"val_miou\"], label=\"Val\")\n",
        "plt.title(\"mIoU (Mean Intersection over Union)\")\n",
        "plt.xlabel(\"√âpocas\")\n",
        "plt.ylabel(\"Valor de mIoU\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkUIWc4N69rx"
      },
      "outputs": [],
      "source": [
        "# Figura 3: Recall\n",
        "print('Recall')\n",
        "\n",
        "med_des(history[\"train_recall\"], 'train')\n",
        "med_des(history[\"val_recall\"], 'val')\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history[\"train_recall\"], label=\"Train\")\n",
        "plt.plot(history[\"val_recall\"], label=\"Val\")\n",
        "plt.title(\"Recall (Sensibilidad)\")\n",
        "plt.xlabel(\"√âpocas\")\n",
        "plt.ylabel(\"Valor de Recall\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mlOwKiRjISp"
      },
      "outputs": [],
      "source": [
        "# Figura 4: Matriz de Confusi√≥n\n",
        "class_names = [\"background\", \"bulk\", \"few-layer\"]\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# --- Evaluaci√≥n sobre el test set ---\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, masks, *_ in test_loader:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits = model(images)  # [B, C, H, W]\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)  # [B, H, W]\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy().ravel())\n",
        "        all_targets.append(masks.cpu().numpy().ravel())\n",
        "\n",
        "# Concatenar todos los p√≠xeles\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_targets = np.concatenate(all_targets)\n",
        "\n",
        "# --- Calcular matriz de confusi√≥n ---\n",
        "cm = confusion_matrix(all_targets, all_preds, labels=list(range(num_classes)))\n",
        "cm_norm = cm.astype(\"float\") / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)  # evita divisi√≥n por 0\n",
        "cm_norm = cm_norm * 100  # convertir a porcentaje\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Clase Predicha (Predicted)\")\n",
        "plt.ylabel(\"Clase Verdadera (True)\")\n",
        "plt.title(\"Matriz de Confusi√≥n (% por Fila)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOwVeEyQOvCd"
      },
      "source": [
        "\n",
        "\n",
        "> **TO DO:** Preprocesamiento (filtrado EJ: Gaussiano) de las imagenes para few-layer, aumentar n√∫mero de epochs, Gr√°fica de Precisi√≥n-Recall, Ajuste hiperpar√°metros en calibraci√≥n.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om3g45N8eoLU"
      },
      "outputs": [],
      "source": [
        "def plot_precision_recall_curve(probas, targets, num_classes, index_to_name):\n",
        "    targets_one_hot = np.eye(num_classes)[targets]\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        precision, recall, _ = precision_recall_curve(targets_one_hot[:, i], probas[:, i])\n",
        "        pr_auc = auc(recall, precision)\n",
        "        plt.plot(recall, precision, lw=2,\n",
        "                 label=f'{index_to_name[i]} (AUC-PR = {pr_auc:.3f})')\n",
        "    plt.ylabel(\"Precision (Sensibilidad)\")\n",
        "    plt.xlabel(\"Recall (Precisi√≥n)\")\n",
        "    plt.title(\"Curva de Precisi√≥n-Recall por Clase\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_calibration_curve(probas, targets, num_classes, index_to_name, n_bins=50):\n",
        "    max_probas = np.max(probas, axis=1)\n",
        "    preds = np.argmax(probas, axis=1)\n",
        "\n",
        "    is_correct = (preds == targets).astype(float)\n",
        "\n",
        "    frac_of_pos, mean_predicted_value = calibration_curve(\n",
        "        is_correct, max_probas, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectamente Calibrado', color='gray')\n",
        "    plt.plot(mean_predicted_value, frac_of_pos, label=f'Modelo (General)', lw=2)\n",
        "\n",
        "    plt.xlabel(\"Confianza Predicha\")\n",
        "    plt.ylabel(\"Precisi√≥n Real\")\n",
        "    plt.title(\"Curva de Calibraci√≥n del Modelo\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "all_probas_flat, all_targets_flat = evaluate_test_final(\n",
        "    test_loader,\n",
        "    model,\n",
        "    num_classes\n",
        ")\n",
        "\n",
        "plot_precision_recall_curve(\n",
        "    all_probas_flat,\n",
        "    all_targets_flat,\n",
        "    num_classes,\n",
        "    index_to_name\n",
        ")\n",
        "\n",
        "plot_calibration_curve(\n",
        "    all_probas_flat,\n",
        "    all_targets_flat,\n",
        "    num_classes,\n",
        "    index_to_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLr5tIUM_Sdf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "provenance": [],
      "collapsed_sections": [
        "a4PWHYAwlE-X",
        "BtNPlUOdIU-7",
        "TEp-wxAaKsKd",
        "Si_i3wezJ5vX",
        "9nrAzde1KfOk",
        "xRXL9d9h6cUk",
        "6xEU2UMT6YI0",
        "OgnHs2ZD6j0N",
        "9FV2_65874-z",
        "yCm0oKIz7-pB",
        "G7kbIBzvL5cj",
        "oc6181rfM9_8",
        "dD1o5ALkNB8a"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}